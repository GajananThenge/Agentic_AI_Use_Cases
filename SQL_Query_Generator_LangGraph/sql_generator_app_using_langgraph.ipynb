{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "from typing_extensions import TypedDict\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import hub\n",
    "from typing_extensions import Annotated\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDatabaseTool\n",
    "\n",
    "from langgraph.graph import START, StateGraph,END\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_ollama.llms import OllamaLLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains'), (6, 'Ant√¥nio Carlos Jobim'), (7, 'Apocalyptica'), (8, 'Audioslave'), (9, 'BackBeat'), (10, 'Billy Cobham')]\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n",
    "db.run(\"SELECT * FROM Artist LIMIT 10;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def query_template():\n",
    "    query_prompt_template = hub.pull(\"langchain-ai/sql-query-system-prompt\")\n",
    "    return query_prompt_template\n",
    "    #query_prompt_template.messages[0].pretty_print()\n",
    "    \n",
    "def my_llm():\n",
    "    llm = init_chat_model(\"llama-3.3-70b-versatile\", model_provider=\"groq\",temperature=0)\n",
    "    # llm = OllamaLLM(\n",
    "    #     model=\"ollama/deepseek-r1:8b\",\n",
    "    #     base_url=\"http://localhost:11434\"\n",
    "    # )\n",
    "    \n",
    "    return llm\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: str\n",
    "    result: str\n",
    "    answer: str\n",
    "\n",
    "\n",
    "class QueryOutput(TypedDict):\n",
    "    \"\"\"Generated SQL query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Syntactically valid SQL query.\"]\n",
    "\n",
    "\n",
    "def write_query(state: State):\n",
    "\n",
    "    query_prompt_template= query_template()\n",
    "    \n",
    "    \"\"\"Generate SQL query to fetch information.\"\"\"\n",
    "    prompt = query_prompt_template.invoke(\n",
    "        {\n",
    "            \"dialect\": db.dialect,\n",
    "            \"top_k\": 10,\n",
    "            \"table_info\": db.get_table_info(),\n",
    "            \"input\": state[\"question\"],\n",
    "        }\n",
    "    )\n",
    "    llm = my_llm()\n",
    "    structured_llm = llm.with_structured_output(QueryOutput)\n",
    "    result = structured_llm.invoke(prompt)\n",
    "    return {\"query\": result[\"query\"]}\n",
    "\n",
    "\n",
    "def execute_query(state: State):\n",
    "    \n",
    "    \"\"\"Execute SQL query.\"\"\"\n",
    "    execute_query_tool = QuerySQLDatabaseTool(db=db)\n",
    "    return {\"result\": execute_query_tool.invoke(state[\"query\"])}\n",
    "\n",
    "\n",
    "def generate_answer(state: State):\n",
    "    \"\"\"Answer question using retrieved information as context.\"\"\"\n",
    "    prompt = (\n",
    "        \"Given the following user question, corresponding SQL query, \"\n",
    "        \"and SQL result, answer the user question.\\n\\n\"\n",
    "        f'Question: {state[\"question\"]}\\n'\n",
    "        f'SQL Query: {state[\"query\"]}\\n'\n",
    "        f'SQL Result: {state[\"result\"]}'\n",
    "    )\n",
    "    llm = my_llm()\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "def analyst(state: State):\n",
    "    \"\"\"Answer question using retrieved information as context.\"\"\"\n",
    "    prompt = (\n",
    "        \"Given the following user question, corresponding SQL query, \"\n",
    "        \"and SQL result, answer the user question.\\n\\n\"\n",
    "        f'Question: {state[\"question\"]}\\n'\n",
    "        f'SQL Query: {state[\"query\"]}\\n'\n",
    "        f'SQL Result: {state[\"result\"]}'\n",
    "    )\n",
    "    llm = my_llm()\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "def create_sql_graph():\n",
    "    # Initialize the StateGraph with the State TypedDict\n",
    "    graph_builder = StateGraph(State).add_sequence(\n",
    "        [write_query, execute_query, generate_answer]\n",
    "    )\n",
    "    \n",
    "    # Add edges to the graph\n",
    "    graph_builder.add_edge(START, \"write_query\")\n",
    "    graph_builder.add_edge(\"generate_answer\", END)\n",
    "\n",
    "    # Create a MemorySaver for persistence\n",
    "    memory = MemorySaver()\n",
    "    \n",
    "    # Compile the graph with the memory checkpointer and specify interrupt points\n",
    "    sql_graph = graph_builder.compile(checkpointer=memory, interrupt_before=[\"execute_query\"])\n",
    "    \n",
    "    # Return the compiled graph and the configuration\n",
    "    config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "    \n",
    "    return sql_graph, config\n",
    "\n",
    "def run_sql_generator(graph,config,ques):\n",
    "    # for step in graph.stream(ques, config,stream_mode=\"updates\"):\n",
    "    #     print(step)\n",
    "    # graph.invoke()\n",
    "    graph.invoke(ques, config)\n",
    "\n",
    "\n",
    "    try:\n",
    "        user_approval = 'yes'#input(\"Do you want to go to execute query? (yes/no): \")\n",
    "    except Exception:\n",
    "        user_approval = \"no\"\n",
    "\n",
    "    if user_approval.lower() == \"yes\":\n",
    "        # If approved, continue the graph execution\n",
    "        for step in graph.stream(None, config, stream_mode=\"updates\"):\n",
    "            print(step),\n",
    "        formatted_answer = f\"#### {step['generate_answer']['answer'].replace(',', '\\n- ')}\"\n",
    "        display(Markdown(formatted_answer))     \n",
    "    else:\n",
    "        print(\"Operation cancelled by user.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques1 = {\"question\": \"what are the different tables available in database? Shownit as bullet points\"}\n",
    "ques2 = {\"question\": \"can you provide the column names in each column in tabular format like tabel_name,Column_name,Description?\"}\n",
    "ques3 = {'question': \"How many different types of Genre? Provide them with number of times it occus in our Genre table \"}\n",
    "ques4 = {'question': \"How many different types of Genre? Provide them with number of times it occus in our Genre table \"}\n",
    "ques5 = {\"question\": \"How many employees are there?\"}\n",
    "ques5 = {\"question\": \"Which is most frequent  BillingCountry?\"}\n",
    "sql_graph, config = create_sql_graph()\n",
    "run_sql_generator(sql_graph,config,ques5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
